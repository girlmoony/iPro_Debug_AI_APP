import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models

# --- モデル準備（284クラスモデルをロード） ---
model = models.efficientnet_b0(pretrained=False)
model.classifier[1] = nn.Linear(model.classifier[1].in_features, 284)
model.load_state_dict(torch.load("sushi_284_model.pth"))  # 既存のモデル

# --- クラス数を288に変更（追加学習用） ---
model.classifier[1] = nn.Linear(model.classifier[1].in_features, 288)

# --- 全層一旦凍結 ---
for param in model.parameters():
    param.requires_grad = False

# --- 出力層だけ解凍（初期状態） ---
for param in model.classifier.parameters():
    param.requires_grad = True

# --- Optimizer + CosineAnnealingLR（120エポックを想定） ---
optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()),
                      lr=0.01, momentum=0.9, weight_decay=1e-4)

scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=120, eta_min=1e-5)

# --- 解凍スケジューラ ---
def unfreeze_schedule(model, epoch):
    if epoch == 15:
        for param in model.features[6].parameters():
            param.requires_grad = True
    elif epoch == 30:
        for param in model.features[5].parameters():
            param.requires_grad = True
    elif epoch == 45:
        for param in model.features[4].parameters():
            param.requires_grad = True
    elif epoch == 60:
        for param in model.features[3].parameters():
            param.requires_grad = True
    # [0]〜[2]は常に固定（再学習しない）

# --- 学習ループ ---
for epoch in range(120):
    unfreeze_schedule(model, epoch)

    model.train()
    for images, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

    scheduler.step()





